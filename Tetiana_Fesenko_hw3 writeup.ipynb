{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caregivers and Machine Learning 2023 \n",
    "#### Homework assignment 3\n",
    "\n",
    "### Problem 1: [25 pts] Conceptual understanding \n",
    "\n",
    "### (A) [5 pts] What is the advantage of using a bagging algorithm like Random Forest over a single Decision Tree? \n",
    "\n",
    "#### Answer: \n",
    "\n",
    "There are a few reasons why using a bagging algorithm like Random Forest has some advantages over using for example a Decision Tree.\n",
    "\n",
    "1. More flexibility. Random Forest is a flexible algorithm with the ability to work with both categorical and continuous features, and can handle different machine learning tasks such as classification and regression problems.\n",
    "2. Accuracy. By combining multiple Decision Trees, Random Forest has the potential to achieve higher predictive accuracy than a single Decision Tree, making it a better choice for many machine learning applications.\n",
    "3. Overfitting prevention. To prevent overfitting, Random Forest constructs several Decision Trees on various subsets of the training data, and randomly selects a subset of features at each split. This strategy mitigates the risk of overfitting that can arise when using a single Decision Tree.\n",
    "4. Handling outliers. Random Forest's randomness in constructing multiple Decision Trees makes it less sensitive to outliers present in the dataset, compared to a single Decision Tree. As a result, it can produce better results on datasets that contain outliers.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (B) [5 pts] What is the purpose of a loss function in machine learning? \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of a loss function in machine learning is to measure the error between the predicted output and the actual output. It quantifies the penalty incurred by the model for making wrong predictions.\n",
    "\n",
    "A loss function provides a way to evaluate how well a machine learning algorithm is performing by comparing the predicted output with the actual output. The goal is to minimize the value of the loss function, which can be achieved via optimization.\n",
    "\n",
    "Optimization is adjusting the parameters of the machine learning model to minimize the value of the loss function. This is done by updating the model's parameters until the loss function is minimized.\n",
    "\n",
    "Different types of machine learning problems require different loss functions. For example, in regression problems, the mean squared error (MSE) loss function is commonly used, while in classification problems, cross-entropy loss is often used. Selection of loss function depends on the nature of the problem and the goals of the machine learning projects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (C) [5 pts] How does an outlier in a small data set affect a linear regression model? How about a large data set?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Small dataset:\n",
    "An outlier can have a significant impact on the Linear Regression model. This is because the model's fitting is sensitive to every data point. As a result of this, the presence of an outlier can lead to a poor fit and incorrect predictions.\n",
    "\n",
    "##### Large dataset:\n",
    "An outlier can have a less significant impact on the Linear Regression model. This is because the model has more data points to learn from. As a result, the influence of any individual data point is greatly reduced. While an outlier can still affect the model's fit to some level, it is less likely to have a significant impact on the model's final accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (D) [5 pts] What is an example of an operation where using a vector is faster than using for loops? Explain why. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, using a vector is faster than using \"for loops\" when we are trying to calculate the sum of two vectors.\n",
    "\n",
    "When using a \"for loop\" to add two vectors element-wise, the loop must iterate over each element in both vectors, perform the addition, and store the result in a new vector. This can be a time-consuming, especially when working with large vectors.\n",
    "\n",
    "On the other hand, using a vector to add two vectors can be performed much faster. For example, in Python, using the NumPy library to add two vectors is much faster than using a for loop. Here's a code example that demostratees the statement:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  8 10 12 14 16]\n",
      "[ 6  8 10 12 14 16]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define two vectors\n",
    "a = np.array([0, 1, 2, 3, 4, 5])\n",
    "b = np.array([6, 7, 8, 9, 10, 11])\n",
    "\n",
    "# Add the two vectors using a \"for loop\"\n",
    "c = np.zeros_like(a)\n",
    "for i in range(len(a)):\n",
    "    c[i] = a[i] + b[i]\n",
    "\n",
    "# Add the two vectors using a vector\n",
    "c_vector = a + b\n",
    "\n",
    "print(c)\n",
    "print(c_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (E) [5 pts] Why is the Sigmoid Function used in Logistic Regression?\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sigmoid Function is used in Logistic Regression to map the output of a linear function to a probability value between 0 and 1, which is then used to make a binary classification decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
